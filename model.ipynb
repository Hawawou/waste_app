{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cardboard', 'plastic', 'paper', 'glass', 'trash', 'metal', 'organic']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations = transforms.Compose(transforms.ToTensor)\n",
    "dataset = ImageFolder(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "squeeze",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     fig\u001b[39m.\u001b[39madd_subplot(rows, cols, i)\n\u001b[1;32m     16\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     plt\u001b[39m.\u001b[39mimshow(img\u001b[39m.\u001b[39;49msqueeze(), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:519\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    512\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    516\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_category\n\u001b[0;32m--> 519\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: squeeze"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMoAAADJCAYAAABi8a0GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACMUlEQVR4nO3TwQ3AIBDAsNL9dz42QPkhJHuCfLJmZj7g6L8dAC8wCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjAKBUSAwCgRGgcAoEBgFAqNAYBQIjALBBrOYBY5PQI7gAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: 'cardboard',\n",
    "    1: 'glass',\n",
    "    2: 'metal',\n",
    "    3: 'organic',\n",
    "    4: 'paper',\n",
    "    5: 'plastic',\n",
    "    6: 'trash',\n",
    "}\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(dataset), size=(1,1)).item()\n",
    "    img, label = dataset[sample_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
